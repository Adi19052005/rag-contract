# Copy this file to .env and fill in your actual values
# Never commit .env files with real credentials to version control

# ============================================
# REQUIRED SETTINGS
# ============================================

# Google Gemini API Configuration (REQUIRED)
# Get your API key from https://ai.google.dev/
GEMINI_API_KEY= add your gemini api key here


# ============================================
# FRONTEND CONFIGURATION
# ============================================

# Primary frontend URL for CORS and redirects
# Frontend dev server runs on port 8080
# Frontend production domain should be configured here
FRONTEND_URL=http://localhost:8080

# CORS allowed origins (comma-separated for production)
# IMPORTANT: Frontend dev server runs on port 8080, add it to CORS origins
# Development: http://localhost:5173,http://localhost:3000,http://localhost:8080
# Production: https://yourdomain.com,https://www.yourdomain.com
CORS_ORIGINS=http://localhost:5173,http://localhost:3000,http://localhost:8080


# ============================================
# FILE UPLOAD SETTINGS
# ============================================

# Maximum file size in MB (recommended: 1-100)
# Note: Larger files consume more memory and processing time
MAX_FILE_SIZE_MB=10

# Allowed file types (comma-separated)
ALLOWED_FILE_TYPES=pdf,docx,txt


# ============================================
# RAG & CHUNKING CONFIGURATION
# ============================================

# Text chunk size for embeddings
CHUNK_SIZE=500

# Overlap between consecutive chunks (for context preservation)
CHUNK_OVERLAP=50

# Number of chunks to retrieve for RAG queries
TOP_K_RESULTS=3

# Embedding model (using Sentence Transformers)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# LLM model to use (Gemini)
LLM_MODEL=gemini-1.5-flash


# ============================================
# SESSION MANAGEMENT
# ============================================

# Maximum session age in hours before automatic cleanup
# Note: Larger values consume more memory (default: 24)
SESSION_MAX_AGE_HOURS=24

# Session cleanup interval in minutes (background task)
SESSION_CLEANUP_INTERVAL_MINUTES=60


# ============================================
# LOGGING CONFIGURATION
# ============================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use DEBUG for development, INFO for production
DEBUG=False
LOG_LEVEL=INFO
LOG_FILE=logs/api.log


# ============================================
# API CONFIGURATION
# ============================================

# API endpoint prefix
API_PREFIX=/api

# Enable API documentation endpoints (/api/docs, /api/redoc)
# Disable in production if you want to hide API documentation
ENABLE_API_DOCS=True


# ============================================
# OPTIONAL: OpenAI Integration (for future use)
# ============================================

# OPENAI_API_KEY=your_openai_api_key_here


# ============================================
# Frontend Integration Notes
# ============================================

# The React frontend (clear-clause-ai-main) connects to this backend
# Ensure CORS_ORIGINS includes the frontend dev server URL (port 8080)
# Frontend expects API at http://localhost:8000/api/*

# To enable the frontend-backend integration:
# 1. Run backend: python src/main.py
# 2. Run frontend: npm run dev (from clear-clause-ai-main directory)
# 3. Frontend will be available at http://localhost:8080
# 4. Verify CORS is properly configured - check browser console for errors


# ============================================
# PRODUCTION DEPLOYMENT NOTES
# ============================================

# 1. Always use environment variables instead of .env in production
# 2. Set DEBUG=False in production
# 3. Use specific CORS_ORIGINS instead of wildcard "*"
# 4. Ensure GEMINI_API_KEY is securely stored (use secrets manager)
# 5. Set LOG_LEVEL=INFO or WARNING in production
# 6. Monitor logs and session cleanup results
# 7. For multiple workers, use persistent session storage (Redis)
