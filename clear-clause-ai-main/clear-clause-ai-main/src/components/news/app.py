from flask import Flask, jsonify
from flask_cors import CORS
import feedparser
import logging
from datetime import datetime
import re

app = Flask(__name__)
CORS(app)

# Disable logging noise
logging.getLogger("urllib3").setLevel(logging.CRITICAL)
logging.getLogger("feedparser").setLevel(logging.CRITICAL)


def extract_image_from_entry(entry):
    """
    Extracts image directly from RSS feed entry.
    Google News RSS includes images in media:content tags.
    """
    try:
        # Debug: Print all available keys in entry
        available_keys = list(entry.keys())
        print(f"      üìã Entry keys: {available_keys}")
        
        # Check for media content (most reliable)
        if hasattr(entry, 'media_content') and entry.media_content:
            for media in entry.media_content:
                if media.get('url'):
                    print(f"      ‚úÖ Found media_content image: {media.get('url')[:60]}")
                    return media.get('url')
        
        # Check for media:thumbnail
        if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
            for thumb in entry.media_thumbnail:
                if thumb.get('url'):
                    print(f"      ‚úÖ Found media_thumbnail image: {thumb.get('url')[:60]}")
                    return thumb.get('url')
        
        # Check for image link
        if hasattr(entry, 'image') and entry.image:
            if hasattr(entry.image, 'url'):
                print(f"      ‚úÖ Found image.url: {entry.image.url[:60]}")
                return entry.image.url
        
        # Check for links with rel="image"
        if hasattr(entry, 'links') and entry.links:
            for link in entry.links:
                if link.get('rel') == 'image' or link.get('type', '').startswith('image/'):
                    print(f"      ‚úÖ Found image link: {link.get('href', '')[:60]}")
                    return link.get('href', '')
        
        # Parse image from summary HTML (fallback)
        summary = entry.get('summary', '')
        if summary and '<img' in summary:
            # Extract src from img tag
            match = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', summary)
            if match:
                img_url = match.group(1)
                if img_url and not any(x in img_url.lower() for x in ['logo', 'favicon', '1x1', 'spacer']):
                    print(f"      ‚úÖ Found image in summary HTML: {img_url[:60]}")
                    return img_url
        
        print(f"      ‚ö†Ô∏è  No image found in entry")
        return ""
    
    except Exception as e:
        print(f"      ‚ùå Error extracting image: {str(e)}")
        return ""


def fetch_news_from_rss(topic: str):
    """
    Fetches news from Google News RSS feed.
    RSS is faster, stable, and never blocked compared to HTML scraping.
    """
    print(f"\nüîç Fetching news from Google News RSS: '{topic}'")
    
    # Google News RSS endpoint
    rss_url = f"https://news.google.com/rss/search?q={topic.replace(' ', '+')}"
    
    try:
        print(f"   üì° URL: {rss_url}")
        
        # Parse the RSS feed
        feed = feedparser.parse(rss_url)
        
        # Check if feed parsed successfully
        if not feed or 'entries' not in feed:
            print(f"   ‚ùå Failed to parse feed")
            return []
        
        print(f"   ‚úÖ Feed parsed successfully, found {len(feed.entries)} entries")
        
        articles = []
        seen_titles = set()
        
        for idx, entry in enumerate(feed.entries[:10]):
            try:
                # Extract basic fields
                title = entry.get('title', '').strip()
                
                # Skip empty or duplicate titles
                if not title or title in seen_titles:
                    continue
                seen_titles.add(title)
                
                # Extract URL
                url = entry.get('link', '')
                
                # Extract description/summary
                description = entry.get('summary', '').strip()
                # Remove HTML tags if present
                if '<' in description and '>' in description:
                    # Remove all HTML tags properly
                    description = re.sub(r'<[^>]+>', '', description).strip()
                
                # Extract published date
                published_date = entry.get('published', 'Recently')
                
                # Extract source (from title sometimes contains source info)
                source = entry.get('source', {}).get('title', 'Google News')
                
                # Extract thumbnail image directly from RSS entry
                image = extract_image_from_entry(entry)
                
                article = {
                    "id": f"{topic.lower()}-{len(articles)}",
                    "title": title,
                    "description": description[:250] if description else title[:200],
                    "url": url,
                    "publishedDate": published_date,
                    "source": source,
                    "image": image,  # Images from RSS feed metadata
                    "topic": topic.lower()
                }
                
                articles.append(article)
                if image:
                    print(f"   ‚úì Article {len(articles)}: {title[:50]}... [üì∏ RSS Image]")
                else:
                    print(f"   ‚úì Article {len(articles)}: {title[:50]}...")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Error parsing entry {idx}: {str(e)}")
                continue
        
        if articles:
            print(f"\n   üéâ SUCCESS! Found {len(articles)} articles for '{topic}'")
            return articles
        else:
            print(f"   ‚ö†Ô∏è  No valid articles extracted from feed")
            return []
    
    except Exception as e:
        print(f"   ‚ùå Error fetching RSS feed: {str(e)}")
        return []


@app.route('/news/<topic>', methods=['GET'])
def get_news(topic):
    """
    GET /news/<topic>
    Fetches news articles for a given topic from Google News RSS feed.
    
    Returns JSON array of articles or 404 error if none found.
    """
    topic_clean = topic.lower().strip()
    
    print(f"\n{'='*70}")
    print(f"üì® NEWS REQUEST: {topic_clean}")
    print(f"{'='*70}")
    
    # Fetch articles from RSS feed
    articles = fetch_news_from_rss(topic_clean)
    
    if not articles:
        error_msg = f"No news found for '{topic_clean}'"
        print(f"\n‚ùå RETURNING ERROR")
        return jsonify({"error": error_msg}), 404
    
    print(f"\n‚úÖ RETURNING {len(articles)} ARTICLES")
    return jsonify(articles), 200


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({"status": "‚úÖ Backend is running!", "port": 8000}), 200


if __name__ == '__main__':
    print("\n" + "="*70)
    print("üöÄ LEGALAI NEWS BACKEND - GOOGLE NEWS RSS FEED")
    print("="*70)
    print("üìç Server: http://localhost:8000")
    print("üì∞ Endpoint: GET /news/<topic>")
    print("üîå Source: Google News RSS (Fast, Stable, Never Blocked)")
    print("\nüí° Examples:")
    print("   ‚Ä¢ http://localhost:8000/news/technology")
    print("   ‚Ä¢ http://localhost:8000/news/ai")
    print("   ‚Ä¢ http://localhost:8000/news/legal")
    print("   ‚Ä¢ http://localhost:8000/news/contracts")
    print("   ‚Ä¢ http://localhost:8000/news/compliance")
    print("   ‚Ä¢ http://localhost:8000/news/artificial+intelligence")
    print("\n‚ú® Features:")
    print("   ‚úì Instant results (RSS is fast)")
    print("   ‚úì Never blocked (official Google feed)")
    print("   ‚úì Stable parsing (RSS format is consistent)")
    print("   ‚úì Production-ready error handling")
    print("="*70 + "\n")
    app.run(debug=False, port=8000, threaded=True)
